In order to see the overall results of this project, you can view 'model comparison figure.png' which provides an overview of each models perfomance. In order to create this figure for yourself, download 'clean_training_data.csv', the five credit risk models and the 'model comparison.py' script. After running the script you will be able to see a brief data visualisation of how well each model performed at predicting whether an individual would default on a loan. 

'Model trainer.py' displays how the intial data file was cleaned along with how each of the first 4 models were made. 'Decision threshold tuner.py' shows how model 4 was modified to create model 5 whilst 'credit risk model analysis.py' was used to measure how well each model performed in isolation. 

It turns out the Models 4 and 5 have the best perfomance as they ended up with the best balance between precision and recall resulting in the highest F1 score. Both models also had a better true postive to false positive ratio in comparsion to the others. These models used the XGBClassifier model from xgboost which faired better when dealing with a data set that was so heavily skewed against loan defaults (as in actuallity such events are very rare as they show up in the dataset about 8% of the time).

**The data used to train these models was sourced from the Kaggle 'Home Credit Default Risk' Competition (https://www.kaggle.com/c/home-credit-default-risk/data)**
